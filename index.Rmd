---
title: "online-grading"
author: "GAN LING"
date: "2017/4/19"
output: 
  html_document: 
    fig_height: 15
    fig_width: 15
---

in this file our original document is KAdebowaleGender_SBU original 050117  test  (1).xlsx.
I open the file using Excel, then sort it according to StudentNumber column
then save it as KAdebowaleGender_SBU.csv file to use

read the data into RStudio

```{r}
grading = read.csv("KAdebowaleGender_SBU.csv")
```


The purpose of this project is to  calculate the correlation between the final grade
1. total Hits  (column CW)

```{r}
data1 = grading[,c("TotalGrade", "TotalDBMFhits")]
```

because the data doesn't have any NA and NULL data, we don't need to deal with that
create training set and test set

```{r}
require(caret)
seed = as.numeric(as.Date("2017-04-19"))
set.seed(seed)
inTrain = createDataPartition(data1$TotalGrade, p=0.7)
trainingset <- data1[inTrain[[1]],]
testset = data1[-inTrain[[1]],]
```

draw the plot about the relationship between them

```{r}
glm.fit = glm(TotalGrade~TotalDBMFhits,data = trainingset)
summary(glm.fit)
plot(trainingset$TotalDBMFhits, trainingset$TotalGrade, xlab="TotalDBMFhits", ylab="TotalGrade")
abline(glm.fit, col="blue", lwd=2)
```

we can also see the correlation rate between them

```{r}
library(lsr)
correlate(trainingset, corr.method="spearman" )
```

then we can use it to test set

```{r}
glm.probs = predict(glm.fit, newdata = testset, type = "response") 
glm.probs[1:5]
glm.pred = as.data.frame(round(glm.probs)) 
colnames(glm.pred) = c("pred")
calacc = function(x, y, error){
    equal = 0
    total = length(x)
    for (i in 1:total){
        upvalue = y[i] + error
        downvalue = y[i] = error
        if (x[i] >= downvalue && x[i] <= upvalue){
            equal = equal + 1
        }
    }
    acc = equal / total 
    acc
}
# calculate the accuracy, the error set to 5 points
calacc(glm.pred$pred, testset$TotalGrade, 5)
```

use CV and loocv to do the model

```{r}
require(boot)
glm.fit = glm(TotalGrade~TotalDBMFhits,data = trainingset)
cv.glm(trainingset,glm.fit)$delta
loocv=function(fit){
  h=lm.influence(fit)$h
  mean((residuals(fit)/(1-h))^2)
}
loocv(glm.fit)

cv.error=rep(0,5)
degree=1:5   ## polomial 1 to 5 degree
for(d in degree){
  glm.fit=glm(TotalGrade~poly(TotalDBMFhits,d), data=trainingset)
  cv.error[d]=loocv(glm.fit)
}
plot(degree,cv.error,type="b")

## 10-fold CV  divide the data 10 parts repeat only 10 times

cv.error10=rep(0,5)
for(d in degree){
  glm.fit=glm(TotalGrade~poly(TotalDBMFhits,d), data=trainingset)
  cv.error10[d]=cv.glm(trainingset,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type="b",col="red")
```

then use SVM model, but nothing insteresting by using this, give up

```{r}
library(e1071)
attach(trainingset)
plot(TotalDBMFhits, col = TotalGrade + 1)
dat = data.frame(TotalGrade=factor(TotalGrade),TotalDBMFhits)
fit = svm(factor(TotalGrade)~.,data=dat,scale=FALSE,kernel="radial",cost=5)

# xgrid = expand.grid(X1=px1,X2=px2)
```

2. total time spent in the course ( Column  T)

```{r}
data2 = grading[,c("TotalGrade", "TotalTimeStudentsspentinCourseinHours")]
```

because the data have NA and NULL data, we need to deal with that

```{r}
cleanNULL = function(x){
   for (i in 1:nrow(x)){
       for (j in 1:ncol(x)){
           if (x[i, j] == "#NULL!"){
              x[i, j] = NA 
           }
       }
   } 
    x
}
data2 = cleanNULL(data2)
data2 = na.omit(data2)
data2$TotalTimeStudentsspentinCourseinHours = as.integer(data2$TotalTimeStudentsspentinCourseinHours)
```

create training set and test set

```{r}
seed = as.numeric(as.Date("2017-04-19"))
set.seed(seed)
inTrain = createDataPartition(data2$TotalGrade, p=0.7)
trainingset <- data2[inTrain[[1]],]
testset = data2[-inTrain[[1]],]
```

draw the plot about the relationship between them

```{r}
glm.fit = glm(TotalGrade~TotalTimeStudentsspentinCourseinHours,data = trainingset)
summary(glm.fit)
plot(trainingset$TotalTimeStudentsspentinCourseinHours, trainingset$TotalGrade, xlab="TotalTimeStudentsspentinCourseinHours", ylab="TotalGrade")
abline(glm.fit, col="blue", lwd=2)
```

we can also see the correlation rate between them

```{r}
correlate(trainingset, corr.method="spearman" )
```

then we can use it to test set

```{r}
glm.probs = predict(glm.fit, newdata = testset, type = "response") 
glm.probs[1:5]
glm.pred = as.data.frame(round(glm.probs)) 
colnames(glm.pred) = c("pred")
# calculate the accuracy, the error set to 0 points
calacc(glm.pred$pred, testset$TotalGrade, 0)
```

use CV and loocv to do the model

```{r}
glm.fit = glm(TotalGrade~TotalTimeStudentsspentinCourseinHours,data = trainingset)
cv.glm(trainingset,glm.fit)$delta
loocv=function(fit){
  h=lm.influence(fit)$h
  mean((residuals(fit)/(1-h))^2)
}
loocv(glm.fit)

cv.error=rep(0,5)
degree=1:5   ## polomial 1 to 5 degree
for(d in degree){
  glm.fit=glm(TotalGrade~poly(TotalTimeStudentsspentinCourseinHours,d), data=trainingset)
  cv.error[d]=loocv(glm.fit)
}
plot(degree,cv.error,type="b")

## 10-fold CV  divide the data 10 parts repeat only 10 times
cv.error10=rep(0,5)
for(d in degree){
  glm.fit=glm(TotalGrade~poly(TotalTimeStudentsspentinCourseinHours,d), data=trainingset)
  cv.error10[d]=cv.glm(trainingset,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type="b",col="red")
```

3. Both   Total Hits and Total Time

```{r}
data3 = grading[,c("TotalGrade", "TotalDBMFhits", "TotalTimeStudentsspentinCourseinHours")]
```

because the data have NA and NULL data, we need to deal with that

```{r}
data3 = cleanNULL(data3)
data3 = na.omit(data3)
data3$TotalTimeStudentsspentinCourseinHours = as.integer(data3$TotalTimeStudentsspentinCourseinHours)
```

create training set and test set

```{r}
seed = as.numeric(as.Date("2017-04-19"))
set.seed(seed)
inTrain = createDataPartition(data3$TotalGrade, p=0.7)
trainingset <- data3[inTrain[[1]],]
testset = data3[-inTrain[[1]],]
```

using glm to do the train

```{r}
glm.fit = glm(TotalGrade~.,data = trainingset)
summary(glm.fit)
```

we can also see the correlation rate between them

```{r}
correlate(trainingset, corr.method="spearman" )
```

then we can use it to test set

```{r}
glm.probs = predict(glm.fit, newdata = testset, type = "response") 
glm.probs[1:5]
glm.pred = as.data.frame(round(glm.probs)) 
colnames(glm.pred) = c("pred")
# calculate the accuracy, the error set to 0 points
calacc(glm.pred$pred, testset$TotalGrade, 0)
```


*from the result we can conclude that total time spent in the course has more correlation with total grade*

then use PCA to do with the data

```{r}
datapca = data3[,c(2,3)]
apply(datapca,2,mean)
apply(datapca,2, var)

pca.out=prcomp(datapca, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
```

*the interesting thing is they are vertical*

to do more, we can redesign the datapca for us:

```{r}
datapca = grading[,c(8:12)]
datapca = cleanNULL(datapca)
datapca = na.omit(datapca)
str(datapca)
datapca$GradeonDiscussionLeader = as.integer(datapca$GradeonDiscussionLeader)
datapca$GradeonAssignment1 = as.integer(datapca$GradeonAssignment1)
datapca$GradeonAssignment2 = as.integer(datapca$GradeonAssignment2)
datapca$GradeonFinalPaper = as.integer(datapca$GradeonFinalPaper)

# then do the pca
apply(datapca,2,mean)
apply(datapca,2, var)

pca.out=prcomp(datapca, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
```

from the result we can see that GradeonAssignment1 is the main infuluencing thing in this five variables, with the PC1 equal to `0.5400030`

also, because the var of this five is not too big, then we can se the scale to FALSE to see that whether there are some differences:

```{r}
pca.out=prcomp(datapca, scale=FALSE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
```

this time the result of them is different from the first one, but GradeonAssignment1 is also the main variable in them with PC1 `0.5926345`